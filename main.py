"""
Insurance Claim Timeline Retrieval System
Main Orchestrator

This system demonstrates:
- Multi-agent orchestration
- Data segmentation & hierarchical indexing
- Summary Index (MapReduce) + Hierarchical Chunk Index
- MCP tool integration
- LLM-as-a-judge evaluation
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import logging

# Import project modules
from src.vector_store.setup import VectorStoreManager
from src.indexing.document_loader import InsuranceClaimLoader
from src.indexing.chunking import HierarchicalChunker
from src.indexing.build_indexes import IndexBuilder
from src.retrieval.hierarchical_retriever import HierarchicalRetriever
from src.agents.langchain_integration import LangChainIntegration
from src.agents.manager_agent import ManagerAgent
from src.agents.summarization_agent import SummarizationAgent
from src.agents.needle_agent import NeedleAgent
from src.mcp.tools import get_all_mcp_tools

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()


class InsuranceClaimSystem:
    """
    Main system orchestrator for Insurance Claim Timeline Retrieval
    """

    def __init__(
        self,
        data_dir: str = "./data",
        chroma_dir: str = "./chroma_db",
        rebuild_indexes: bool = False
    ):
        """
        Initialize the Insurance Claim System

        Args:
            data_dir: Directory containing claim documents
            chroma_dir: Directory for ChromaDB persistence
            rebuild_indexes: Whether to rebuild indexes from scratch
        """
        logger.info("=" * 70)
        logger.info("Initializing Insurance Claim Timeline Retrieval System")
        logger.info("=" * 70)

        self.data_dir = Path(data_dir)
        self.chroma_dir = Path(chroma_dir)

        # Check for OpenAI API key
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY not found in environment variables. Please set it in .env file")

        # Initialize components
        self._initialize_system(rebuild_indexes)

        logger.info("System initialization complete!")
        logger.info("=" * 70)

    def _initialize_system(self, rebuild_indexes: bool):
        """Initialize all system components"""

        # 1. Initialize Vector Store Manager
        logger.info("\n[1/8] Initializing Vector Store Manager...")
        self.vsm = VectorStoreManager(persist_dir=str(self.chroma_dir))

        if rebuild_indexes:
            logger.info("Rebuilding indexes - resetting collections...")
            self.vsm.reset_collections()

        # 2. Load Documents
        logger.info("\n[2/8] Loading insurance claim documents...")
        self.loader = InsuranceClaimLoader(data_dir=str(self.data_dir))
        self.documents = self.loader.load_all_documents()
        logger.info(f"Loaded {len(self.documents)} document sections")

        # Print summary
        summary = self.loader.get_document_summary()
        logger.info(f"Document Summary: {summary}")

        # 3. Create Hierarchical Chunks
        logger.info("\n[3/8] Creating hierarchical chunks...")
        self.chunker = HierarchicalChunker(
            chunk_sizes=[2048, 512, 128],  # large, medium, small
            chunk_overlap_ratio=0.2
        )
        self.nodes = self.chunker.chunk_documents(self.documents)

        # 4. Build Indexes
        logger.info("\n[4/8] Building indexes...")
        self.index_builder = IndexBuilder(self.vsm)

        # Check if indexes already exist
        stats = self.vsm.get_collection_stats()
        summary_exists = stats.get('summary', {}).get('count', 0) > 0
        hier_exists = stats.get('hierarchical', {}).get('count', 0) > 0

        if rebuild_indexes or not (summary_exists and hier_exists):
            logger.info("Building Summary Index with MapReduce...")
            self.summary_index = self.index_builder.build_summary_index(self.documents)

            logger.info("Building Hierarchical Index...")
            self.hierarchical_index, self.nodes = self.index_builder.build_hierarchical_index(self.nodes)
        else:
            logger.info("Loading existing indexes from ChromaDB...")
            # Load existing indexes (simplified for demo)
            from llama_index.core import VectorStoreIndex
            summary_collection = self.vsm.get_summary_collection()
            hier_collection = self.vsm.get_hierarchical_collection()

            summary_storage = self.vsm.create_storage_context(summary_collection)
            hier_storage = self.vsm.create_storage_context(hier_collection)

            self.summary_index = VectorStoreIndex.from_vector_store(
                summary_storage.vector_store
            )
            self.hierarchical_index = VectorStoreIndex.from_vector_store(
                hier_storage.vector_store
            )

        # 5. Create Retrievers
        logger.info("\n[5/8] Creating retrievers...")
        self.hier_retriever = HierarchicalRetriever(self.hierarchical_index, self.nodes)

        # 6. Create MCP Tools
        logger.info("\n[6/8] Initializing MCP tools...")
        self.mcp_tools = get_all_mcp_tools()
        logger.info(f"Loaded {len(self.mcp_tools)} MCP tools")

        # 7. Create LangChain Integration
        logger.info("\n[7/8] Setting up LangChain integration...")
        self.integration = LangChainIntegration(
            summary_index=self.summary_index,
            hierarchical_retriever=self.hier_retriever,
            mcp_tools=self.mcp_tools
        )
        self.all_tools = self.integration.get_all_tools()

        # 8. Initialize Agents
        logger.info("\n[8/8] Initializing agents...")

        # Manager Agent (router)
        self.manager_agent = ManagerAgent(tools=self.all_tools)

        # Specialist Agents
        self.summarization_agent = SummarizationAgent(
            summary_index=self.summary_index
        )
        from langchain_openai import ChatOpenAI
        self.needle_agent = NeedleAgent(
            hierarchical_retriever=self.hier_retriever,
            llm=ChatOpenAI(model="gpt-4", temperature=0)
        )

    def query(self, query: str, use_manager: bool = True) -> dict:
        """
        Query the system

        Args:
            query: User query
            use_manager: Whether to use manager agent (True) or direct routing (False)

        Returns:
            Response dictionary
        """
        logger.info(f"\n{'=' * 70}")
        logger.info(f"QUERY: {query}")
        logger.info(f"{'=' * 70}")

        if use_manager:
            # Use manager agent for intelligent routing
            result = self.manager_agent.query(query)
        else:
            # Direct routing based on simple keywords
            query_lower = query.lower()
            if any(word in query_lower for word in ['summarize', 'overview', 'timeline', 'what happened']):
                result = self.summarization_agent.query(query)
            elif any(word in query_lower for word in ['exact', 'specific', 'how much', 'when', 'who']):
                result = self.needle_agent.query(query)
            else:
                result = self.manager_agent.query(query)

        logger.info(f"\nRESPONSE: {result.get('output', 'No output')[:500]}...")

        return result

    def get_statistics(self) -> dict:
        """Get system statistics"""
        stats = self.vsm.get_collection_stats()
        return {
            "documents_loaded": len(self.documents),
            "hierarchical_chunks": len(self.nodes),
            "chroma_stats": stats,
            "available_tools": len(self.all_tools),
            "tool_names": [t.name for t in self.all_tools]
        }


def main():
    """Main entry point"""
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë  Insurance Claim Timeline Retrieval System               ‚ïë
    ‚ïë  Multi-Agent GenAI System with MCP Integration           ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)

    # Initialize system
    # Set rebuild_indexes=True for first run or to refresh data
    system = InsuranceClaimSystem(
        data_dir="./data",
        chroma_dir="./chroma_db",
        rebuild_indexes=False  # Set to True to rebuild
    )

    # Print system statistics
    stats = system.get_statistics()
    print("\n=== System Statistics ===")
    for key, value in stats.items():
        if key != "chroma_stats":
            print(f"{key}: {value}")

    print("\n" + "=" * 70)
    print("System ready! Example queries:")
    print("=" * 70)

    # Example queries
    example_queries = [
        "What is this insurance claim about?",
        "What was the exact deductible amount?",
        "When did the accident occur?",
        "Summarize the timeline of events",
        "Who was the claims adjuster?",
        "What was the total repair cost?",
        "What did the witnesses say?",
        "How many days between the incident and claim filing?"
    ]

    print("\nExample queries you can try:")
    for i, q in enumerate(example_queries, 1):
        print(f"{i}. {q}")

    print("\n" + "=" * 70)
    print("Interactive mode - enter your queries (or 'quit' to exit)")
    print("=" * 70 + "\n")

    # Interactive query loop
    while True:
        try:
            user_query = input("\nüîç Your query: ").strip()

            if user_query.lower() in ['quit', 'exit', 'q']:
                print("\nüëã Goodbye!")
                break

            if not user_query:
                continue

            # Process query
            result = system.query(user_query, use_manager=True)

            # Display result
            print("\n" + "=" * 70)
            print("üìä RESPONSE:")
            print("=" * 70)
            print(result.get('output', 'No response generated'))

            if result.get('intermediate_steps'):
                print("\n" + "-" * 70)
                print("üîß Tools Used:")
                print("-" * 70)
                for step in result['intermediate_steps']:
                    if len(step) >= 2:
                        action, observation = step[0], step[1]
                        print(f"‚Ä¢ {action.tool}: {action.tool_input}")

        except KeyboardInterrupt:
            print("\n\nüëã Goodbye!")
            break
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            logger.error(f"Error in query loop: {e}", exc_info=True)


if __name__ == "__main__":
    main()
